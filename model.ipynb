{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pydicom\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pydicom.pixel_data_handlers.util import convert_color_space\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "# Load CSV data\n",
    "train_df = pd.read_csv(\"/kaggle/input/rsna-breast-cancer-detection/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/rsna-breast-cancer-detection/test.csv\")\n",
    "\n",
    "# DICOM Dataset class\n",
    "class RSNADataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        patient_id = row['patient_id']\n",
    "        image_id = row['image_id']\n",
    "        \n",
    "        # Create file path for DICOM images\n",
    "        dicom_path = os.path.join(self.img_dir, str(patient_id), f\"{image_id}.dcm\")\n",
    "        \n",
    "        if not os.path.exists(dicom_path):\n",
    "            print(f\"File not found: {dicom_path}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Read DICOM file using pydicom and handle compressed DICOMs\n",
    "        try:\n",
    "            dicom_img = pydicom.dcmread(dicom_path, force=True)\n",
    "            dicom_img = dicom_img.pixel_array\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read DICOM file: {dicom_path}, Error: {e}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Convert image to torch tensor and cast to float32 for normalization\n",
    "        dicom_img = torch.tensor(dicom_img, dtype=torch.float32).unsqueeze(0).repeat(3, 1, 1)\n",
    "\n",
    "        if self.transform:\n",
    "            dicom_img = self.transform(dicom_img)\n",
    "\n",
    "        label = row['cancer'] if 'cancer' in row else -1  # No label for test set\n",
    "        return dicom_img, label\n",
    "\n",
    "# Define the transformation (resizing, normalization)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets using the train and test DICOM image paths\n",
    "train_images_dir = \"/kaggle/input/rsna-breast-cancer-detection/train_images\"\n",
    "test_images_dir = \"/kaggle/input/rsna-breast-cancer-detection/test_images\"\n",
    "\n",
    "train_dataset = RSNADataset(df=train_df, img_dir=train_images_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "\n",
    "# Simple model (using ResNet18 as an example)\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.model = resnet18(weights='IMAGENET1K_V1')\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 1)  # Output: binary\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "device = xm.xla_device()  # Use TPU device\n",
    "model = SimpleModel().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_one_epoch(loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(loader):\n",
    "        if images is None:  # Skip batches with None\n",
    "            continue\n",
    "        images = images.to(device, dtype=torch.float32)  # Ensure input is float32\n",
    "        labels = labels.to(device, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        xm.optimizer_step(optimizer)  # TPU optimizer step\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "# Run a small batch prediction\n",
    "def predict(loader, model):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in loader:\n",
    "            if images is None:\n",
    "                continue\n",
    "            images = images.to(device, dtype=torch.float32)  # Ensure input is float32\n",
    "            outputs = model(images)\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "# Training and prediction example\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_one_epoch(train_loader, model, criterion, optimizer)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss}\")\n",
    "\n",
    "# Test prediction on a small batch\n",
    "test_dataset = RSNADataset(df=test_df, img_dir=test_images_dir, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4)\n",
    "\n",
    "# Get predictions\n",
    "predictions = predict(test_loader, model)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
