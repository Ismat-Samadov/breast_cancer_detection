{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ismetsemedov/rsna-screening-mammography-breast-cancer-detection?scriptVersionId=205962738\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"1a2fe382","metadata":{"execution":{"iopub.execute_input":"2024-11-08T13:00:19.655859Z","iopub.status.busy":"2024-11-08T13:00:19.655497Z","iopub.status.idle":"2024-11-08T13:00:30.819766Z","shell.execute_reply":"2024-11-08T13:00:30.818573Z"},"papermill":{"duration":11.171074,"end_time":"2024-11-08T13:00:30.82188","exception":false,"start_time":"2024-11-08T13:00:19.650806","status":"completed"},"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n"]},{"name":"stdout","output_type":"stream","text":["Initializing RSNA Mammography Preprocessing...\n","Total images to process: 54706\n","\n","Processing images...\n","\n","Processing metadata shape: (5, 14)\n","Sample row:\n","site_id                            2\n","patient_id                     10006\n","image_id                   462822612\n","laterality                         L\n","view                              CC\n","age                             61.0\n","cancer                             0\n","biopsy                             0\n","invasive                           0\n","BIRADS                           NaN\n","implant                            0\n","density                          NaN\n","machine_id                        29\n","difficult_negative_case        False\n","Name: 0, dtype: object\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59abecc0a4be46fa9cd29d54c88dcfbf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Reading DICOM from: /kaggle/input/rsna-breast-cancer-detection/train_images/10006/462822612.dcm\n","Reading DICOM from: /kaggle/input/rsna-breast-cancer-detection/train_images/10006/1459541791.dcm\n","Reading DICOM from: /kaggle/input/rsna-breast-cancer-detection/train_images/10006/1864590858.dcm\n","Reading DICOM from: /kaggle/input/rsna-breast-cancer-detection/train_images/10006/1874946579.dcm\n","Reading DICOM from: /kaggle/input/rsna-breast-cancer-detection/train_images/10011/220375232.dcm\n","\n","Processing completed:\n","Successfully processed: 5\n","Failed: 0\n","\n","Processing summary saved.\n","\n","Output directory structure:\n","/kaggle/working/processed_images/\n","├── CC/\n","│   ├── L/\n","│   └── R/\n","├── MLO/\n","│   ├── L/\n","│   └── R/\n","└── processing_summary.csv\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import pydicom\n","import cv2\n","from pathlib import Path\n","from sklearn.model_selection import GroupKFold\n","import albumentations as A\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","\n","class RSNAPreprocessor:\n","    def __init__(self, **kwargs):\n","        \"\"\"\n","        Initialize the preprocessor\n","        \n","        Args:\n","            base_path (str): Base path to the RSNA dataset\n","            target_size (tuple): Target size for resizing images\n","            output_format (str): Format to save processed images\n","        \"\"\"\n","        self.base_path = Path(kwargs.get('base_path', \"/kaggle/input/rsna-breast-cancer-detection\"))\n","        self.target_size = kwargs.get('target_size', (2048, 2048))\n","        self.output_format = kwargs.get('output_format', 'png').lower()\n","        \n","        self.train_images_path = self.base_path / \"train_images\"\n","        self.test_images_path = self.base_path / \"test_images\"\n","        \n","        if self.output_format not in ['png', 'jpg', 'jpeg']:\n","            raise ValueError(\"output_format must be 'png' or 'jpg'/'jpeg'\")\n","\n","    def get_dicom_path(self, patient_id, image_id, is_train=True):\n","        \"\"\"\n","        Get the path to a DICOM file\n","        \"\"\"\n","        images_path = self.train_images_path if is_train else self.test_images_path\n","        return images_path / str(patient_id) / f\"{image_id}\"\n","\n","    def read_dicom(self, patient_id, image_id, is_train=True):\n","        \"\"\"\n","        Read and preprocess DICOM image\n","        \"\"\"\n","        dicom_path = self.get_dicom_path(patient_id, image_id, is_train)\n","        try:\n","            # Add .dcm extension if not in the image_id\n","            if not str(dicom_path).endswith('.dcm'):\n","                dicom_path = Path(str(dicom_path) + '.dcm')\n","\n","            print(f\"Reading DICOM from: {dicom_path}\")  # Debug print\n","            \n","            if not dicom_path.exists():\n","                print(f\"File not found: {dicom_path}\")\n","                return None\n","                \n","            dicom = pydicom.dcmread(dicom_path)\n","            \n","            # Process image\n","            img = dicom.pixel_array\n","            \n","            # Convert to float and normalize\n","            img = img.astype(float)\n","            if img.max() != img.min():\n","                img = (img - img.min()) / (img.max() - img.min())\n","            \n","            # Scale to 0-255 range\n","            img = (img * 255).astype(np.uint8)\n","            \n","            # Apply CLAHE for better contrast\n","            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","            img = clahe.apply(img)\n","            \n","            # Resize while maintaining aspect ratio\n","            aspect = img.shape[0] / img.shape[1]\n","            if aspect > 1:\n","                new_height = self.target_size[0]\n","                new_width = int(new_height / aspect)\n","            else:\n","                new_width = self.target_size[1]\n","                new_height = int(new_width * aspect)\n","            \n","            img = cv2.resize(img, (new_width, new_height))\n","            \n","            # Add padding to reach target size\n","            top_pad = (self.target_size[0] - img.shape[0]) // 2\n","            bottom_pad = self.target_size[0] - img.shape[0] - top_pad\n","            left_pad = (self.target_size[1] - img.shape[1]) // 2\n","            right_pad = self.target_size[1] - img.shape[1] - left_pad\n","            \n","            img = cv2.copyMakeBorder(\n","                img, top_pad, bottom_pad, left_pad, right_pad,\n","                cv2.BORDER_CONSTANT, value=0\n","            )\n","            \n","            return img\n","\n","        except Exception as e:\n","            print(f\"Error processing image {image_id} for patient {patient_id}: {str(e)}\")\n","            return None\n","\n","    def save_image(self, img, output_path):\n","        \"\"\"\n","        Save processed image in specified format\n","        \"\"\"\n","        if img is not None:\n","            if self.output_format == 'png':\n","                cv2.imwrite(str(output_path.with_suffix('.png')), img)\n","            else:  # jpg/jpeg\n","                cv2.imwrite(str(output_path.with_suffix('.jpg')), img, [cv2.IMWRITE_JPEG_QUALITY, 100])\n","\n","    def process_and_save(self, metadata_df, output_dir, num_samples=None):\n","        \"\"\"\n","        Process images and save them in the specified format\n","        \"\"\"\n","        if num_samples:\n","            metadata_df = metadata_df.head(num_samples)\n","        \n","        # Create output directory structure\n","        output_dir = Path(output_dir)\n","        output_dir.mkdir(exist_ok=True)\n","        \n","        # Create subdirectories for different views\n","        for view in ['CC', 'MLO']:\n","            (output_dir / view).mkdir(exist_ok=True)\n","            (output_dir / view / 'L').mkdir(exist_ok=True)\n","            (output_dir / view / 'R').mkdir(exist_ok=True)\n","        \n","        processed_count = 0\n","        failed_count = 0\n","        \n","        print(\"\\nProcessing metadata shape:\", metadata_df.shape)\n","        print(\"Sample row:\")\n","        print(metadata_df.iloc[0])\n","        \n","        for idx, row in tqdm(metadata_df.iterrows(), total=len(metadata_df)):\n","            try:\n","                img = self.read_dicom(\n","                    patient_id=str(row['patient_id']),\n","                    image_id=str(row['image_id'])\n","                )\n","                \n","                if img is not None:\n","                    # Create organized directory structure based on view and laterality\n","                    view = row['view']      # CC or MLO\n","                    laterality = row['laterality']  # L or R\n","                    \n","                    # Define output path with organized structure\n","                    output_path = output_dir / view / laterality / f\"{row['patient_id']}_{row['image_id']}\"\n","                    \n","                    # Save the image\n","                    self.save_image(img, output_path)\n","                    processed_count += 1\n","                    \n","                    # Save a thumbnail for quick viewing\n","                    thumbnail = cv2.resize(img, (512, 512))\n","                    thumbnail_path = output_path.with_name(f\"{output_path.stem}_thumb\")\n","                    self.save_image(thumbnail, thumbnail_path)\n","                    \n","                else:\n","                    failed_count += 1\n","                    \n","            except Exception as e:\n","                failed_count += 1\n","                print(f\"Error processing row {idx}: {str(e)}\")\n","                continue\n","                \n","        return processed_count, failed_count\n","\n","def main():\n","    print(\"Initializing RSNA Mammography Preprocessing...\")\n","    \n","    # Initialize preprocessor with named parameters\n","    preprocessor = RSNAPreprocessor(\n","        base_path=\"/kaggle/input/rsna-breast-cancer-detection\",\n","        target_size=(2048, 2048),\n","        output_format='png'\n","    )\n","    \n","    try:\n","        # Read metadata\n","        train_df = pd.read_csv(\"/kaggle/input/rsna-breast-cancer-detection/train.csv\")\n","        print(f\"Total images to process: {len(train_df)}\")\n","        \n","        # Create output directory\n","        output_dir = Path(\"/kaggle/working/processed_images\")\n","        \n","        # Process images\n","        print(\"\\nProcessing images...\")\n","        processed_count, failed_count = preprocessor.process_and_save(\n","            train_df,\n","            output_dir,\n","            num_samples=5\n","        )\n","        \n","        print(f\"\\nProcessing completed:\")\n","        print(f\"Successfully processed: {processed_count}\")\n","        print(f\"Failed: {failed_count}\")\n","        \n","        # Save processing summary\n","        summary = {\n","            'total_images': len(train_df),\n","            'processed': processed_count,\n","            'failed': failed_count,\n","            'success_rate': processed_count / (processed_count + failed_count) * 100 if (processed_count + failed_count) > 0 else 0\n","        }\n","        \n","        pd.DataFrame([summary]).to_csv(output_dir / 'processing_summary.csv', index=False)\n","        print(\"\\nProcessing summary saved.\")\n","        \n","        print(\"\\nOutput directory structure:\")\n","        print(f\"{output_dir}/\")\n","        print(\"├── CC/\")\n","        print(\"│   ├── L/\")\n","        print(\"│   └── R/\")\n","        print(\"├── MLO/\")\n","        print(\"│   ├── L/\")\n","        print(\"│   └── R/\")\n","        print(\"└── processing_summary.csv\")\n","        \n","    except Exception as e:\n","        print(f\"\\nAn error occurred: {str(e)}\")\n","        import traceback\n","        print(traceback.format_exc())\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","execution_count":null,"id":"3c382001","metadata":{"papermill":{"duration":0.003042,"end_time":"2024-11-08T13:00:30.828571","exception":false,"start_time":"2024-11-08T13:00:30.825529","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"645d017f","metadata":{"papermill":{"duration":0.002839,"end_time":"2024-11-08T13:00:30.834565","exception":false,"start_time":"2024-11-08T13:00:30.831726","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"9b77ae7e","metadata":{"papermill":{"duration":0.002873,"end_time":"2024-11-08T13:00:30.840622","exception":false,"start_time":"2024-11-08T13:00:30.837749","status":"completed"},"tags":[]},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"672bf69c","metadata":{"papermill":{"duration":0.002859,"end_time":"2024-11-08T13:00:30.846569","exception":false,"start_time":"2024-11-08T13:00:30.84371","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":4629629,"sourceId":39272,"sourceType":"competition"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":14.476204,"end_time":"2024-11-08T13:00:31.468879","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-11-08T13:00:16.992675","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"03ed6fba0de94b8980760817bc8e5f2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e689563f97914351a796b09c8ad1b528","placeholder":"​","style":"IPY_MODEL_8af4c91475e7461dacf4077b45757a4b","value":" 5/5 [00:07&lt;00:00,  1.22s/it]"}},"59abecc0a4be46fa9cd29d54c88dcfbf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_624267d4e64a49edaf0f042895490d49","IPY_MODEL_aabe5c3016b3447a8beb59e56ae5bda9","IPY_MODEL_03ed6fba0de94b8980760817bc8e5f2b"],"layout":"IPY_MODEL_797be5b3810843818b333ac6d135c17a"}},"624267d4e64a49edaf0f042895490d49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a635e11c46fd4ec987258b25aab92661","placeholder":"​","style":"IPY_MODEL_9a5de926340944129b4044375e1aa989","value":"100%"}},"797be5b3810843818b333ac6d135c17a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8af4c91475e7461dacf4077b45757a4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a5de926340944129b4044375e1aa989":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a635e11c46fd4ec987258b25aab92661":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aabe5c3016b3447a8beb59e56ae5bda9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e36ec16649004294a1dba492f4b10c4d","max":5.0,"min":0.0,"orientation":"horizontal","style":"IPY_MODEL_ecd8158ba9fd4a1fa00ca8460b38f47e","value":5.0}},"e36ec16649004294a1dba492f4b10c4d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e689563f97914351a796b09c8ad1b528":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecd8158ba9fd4a1fa00ca8460b38f47e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat":4,"nbformat_minor":5}